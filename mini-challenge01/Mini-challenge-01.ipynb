{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Mini-Challenge 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To use [QuickDraw dataset](https://quickdraw.withgoogle.com) to do image classification with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation with Keras using TF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Input, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.5.0-dev20171016\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use **40 classes** and **10K dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes40 = ['airplane','alarm clock','ambulance','angel','ant','anvil','apple','axe','banana','bandage','barn','baseball bat','baseball',\n",
    "           'basket','basketball','bathtub','beach','bear','beard','bed','bee','belt','bicycle','binoculars','birthday cake','blueberry',\n",
    "           'book','boomerang','bottlecap','bowtie','bracelet','brain','bread','broom','bulldozer','bus','bus','butterfly','cactus','cake']\n",
    "num_classes = len(classes40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples_per_class = 10000 # 10k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.load('data/x_data_40_classes_10k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [np.full((num_examples_per_class,), classes40.index(qdraw)) for qdraw in classes40]\n",
    "\n",
    "y_data = np.concatenate(labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we shuffle the train and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data, y_data = unison_shuffled_copies(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "total_size = x_data.shape[0]\n",
    "\n",
    "num_pred = int(0.1 * total_size)              # set 10 % for testing \n",
    "num_validate = int(0.3 * total_size)          # set 30 % for validation\n",
    "num_train = int(0.6 * total_size)             # set 60 % for training\n",
    "\n",
    "x_train = x_data[0:num_train]\n",
    "y_train = y_data[0:num_train]\n",
    "\n",
    "x_test = x_data[num_train:(num_train+num_validate)]\n",
    "y_test = y_data[num_train:(num_train+num_validate)]\n",
    "\n",
    "x_pred = x_data[(num_train+num_validate):]\n",
    "y_pred = y_data[(num_train+num_validate):]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_pred = x_pred.reshape(x_pred.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 28, 28, 1)\n",
      "240000 train samples\n",
      "120000 test samples\n",
      "40000 pred samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_pred = x_pred.astype('float32')\n",
    "\n",
    "# normalize the image to 0 to 1\n",
    "x_train /= 255   \n",
    "x_test /= 255\n",
    "x_pred /= 255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_pred.shape[0], 'pred samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot encoding for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_01 (Conv2D)             (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "Conv_02 (Conv2D)             (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "MaxPool_01 (MaxPooling2D)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout_01 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten_01 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "Dense_01 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "Dropout_02 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense_02 (Dense)             (None, 40)                5160      \n",
      "=================================================================\n",
      "Total params: 1,204,264\n",
      "Trainable params: 1,204,008\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(input_shape) # 8000, 28, 28, 1\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu', name='Conv_01')(Inp)\n",
    "x = Conv2D(64, (3, 3), activation='relu', name='Conv_02')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), name = 'MaxPool_01')(x)\n",
    "x = Dropout(0.2, name='Dropout_01')(x)\n",
    "x = Flatten(name='Flatten_01')(x)\n",
    "x = Dense(128, activation='relu', name='Dense_01')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2, name = 'Dropout_02')(x)\n",
    "output = Dense(num_classes, activation='softmax', name='Dense_02')(x)\n",
    "model = Model(Inp, output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_epochs = 50\n",
    "batch_sizes = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    if epoch<7:\n",
    "        return 0.003    \n",
    "    if epoch<15:\n",
    "        return 0.0015\n",
    "    if epoch<30:\n",
    "        return 0.001   \n",
    "    return 0.0005\n",
    "\n",
    "lrate=LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam()\n",
    "model.compile( loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ready to train.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240000 samples, validate on 120000 samples\n",
      "Epoch 1/50\n",
      "240000/240000 [==============================] - 91s - loss: 1.1812 - acc: 0.6904 - val_loss: 1.0376 - val_acc: 0.7690\n",
      "Epoch 2/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.8175 - acc: 0.7780 - val_loss: 0.7371 - val_acc: 0.7991\n",
      "Epoch 3/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.7130 - acc: 0.8023 - val_loss: 0.6971 - val_acc: 0.8096\n",
      "Epoch 4/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.6526 - acc: 0.8165 - val_loss: 0.7232 - val_acc: 0.8084\n",
      "Epoch 5/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.6048 - acc: 0.8276 - val_loss: 0.6844 - val_acc: 0.8155\n",
      "Epoch 6/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.5684 - acc: 0.8353 - val_loss: 0.6898 - val_acc: 0.8170\n",
      "Epoch 7/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.5366 - acc: 0.8439 - val_loss: 0.6846 - val_acc: 0.8173\n",
      "Epoch 8/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.4657 - acc: 0.8612 - val_loss: 0.6713 - val_acc: 0.8229\n",
      "Epoch 9/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.4436 - acc: 0.8666 - val_loss: 0.6758 - val_acc: 0.8220\n",
      "Epoch 10/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.4260 - acc: 0.8707 - val_loss: 0.6945 - val_acc: 0.8214\n",
      "Epoch 11/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.4140 - acc: 0.8731 - val_loss: 0.7046 - val_acc: 0.8204\n",
      "Epoch 12/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.4014 - acc: 0.8763 - val_loss: 0.7093 - val_acc: 0.8200\n",
      "Epoch 13/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3883 - acc: 0.8786 - val_loss: 0.7154 - val_acc: 0.8181\n",
      "Epoch 14/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3761 - acc: 0.8825 - val_loss: 0.7278 - val_acc: 0.8182\n",
      "Epoch 15/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.3684 - acc: 0.8839 - val_loss: 0.7394 - val_acc: 0.8156\n",
      "Epoch 16/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3398 - acc: 0.8919 - val_loss: 0.7312 - val_acc: 0.8196\n",
      "Epoch 17/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3292 - acc: 0.8952 - val_loss: 0.7428 - val_acc: 0.8185\n",
      "Epoch 18/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3199 - acc: 0.8972 - val_loss: 0.7502 - val_acc: 0.8186\n",
      "Epoch 19/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3131 - acc: 0.8989 - val_loss: 0.7588 - val_acc: 0.8183\n",
      "Epoch 20/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.3067 - acc: 0.9007 - val_loss: 0.7606 - val_acc: 0.8188\n",
      "Epoch 21/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.3017 - acc: 0.9018 - val_loss: 0.7767 - val_acc: 0.8175\n",
      "Epoch 22/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2968 - acc: 0.9032 - val_loss: 0.7871 - val_acc: 0.8166\n",
      "Epoch 23/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2923 - acc: 0.9048 - val_loss: 0.7782 - val_acc: 0.8161\n",
      "Epoch 24/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.2849 - acc: 0.9059 - val_loss: 0.7963 - val_acc: 0.8170\n",
      "Epoch 25/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2833 - acc: 0.9069 - val_loss: 0.7968 - val_acc: 0.8167\n",
      "Epoch 26/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2777 - acc: 0.9084 - val_loss: 0.8059 - val_acc: 0.8166\n",
      "Epoch 27/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2755 - acc: 0.9092 - val_loss: 0.8036 - val_acc: 0.8160\n",
      "Epoch 28/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2697 - acc: 0.9111 - val_loss: 0.8077 - val_acc: 0.8147\n",
      "Epoch 29/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2675 - acc: 0.9112 - val_loss: 0.8208 - val_acc: 0.8160\n",
      "Epoch 30/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2627 - acc: 0.9131 - val_loss: 0.8261 - val_acc: 0.8156\n",
      "Epoch 31/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2448 - acc: 0.9190 - val_loss: 0.8161 - val_acc: 0.8171\n",
      "Epoch 32/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2379 - acc: 0.9215 - val_loss: 0.8243 - val_acc: 0.8168\n",
      "Epoch 33/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2349 - acc: 0.9216 - val_loss: 0.8295 - val_acc: 0.8177\n",
      "Epoch 34/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2311 - acc: 0.9234 - val_loss: 0.8247 - val_acc: 0.8164\n",
      "Epoch 35/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2285 - acc: 0.9239 - val_loss: 0.8363 - val_acc: 0.8171\n",
      "Epoch 36/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2261 - acc: 0.9248 - val_loss: 0.8439 - val_acc: 0.8167\n",
      "Epoch 37/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2249 - acc: 0.9245 - val_loss: 0.8489 - val_acc: 0.8168\n",
      "Epoch 38/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2240 - acc: 0.9258 - val_loss: 0.8387 - val_acc: 0.8154\n",
      "Epoch 39/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2230 - acc: 0.9255 - val_loss: 0.8578 - val_acc: 0.8159\n",
      "Epoch 40/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2210 - acc: 0.9259 - val_loss: 0.8648 - val_acc: 0.8154\n",
      "Epoch 41/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2177 - acc: 0.9273 - val_loss: 0.8587 - val_acc: 0.8159\n",
      "Epoch 42/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2170 - acc: 0.9273 - val_loss: 0.8635 - val_acc: 0.8157\n",
      "Epoch 43/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2137 - acc: 0.9281 - val_loss: 0.8635 - val_acc: 0.8155\n",
      "Epoch 44/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2110 - acc: 0.9296 - val_loss: 0.8680 - val_acc: 0.8159\n",
      "Epoch 45/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2109 - acc: 0.9293 - val_loss: 0.8773 - val_acc: 0.8155\n",
      "Epoch 46/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2098 - acc: 0.9295 - val_loss: 0.8691 - val_acc: 0.8146\n",
      "Epoch 47/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2066 - acc: 0.9304 - val_loss: 0.8789 - val_acc: 0.8162\n",
      "Epoch 48/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2065 - acc: 0.9304 - val_loss: 0.8789 - val_acc: 0.8162\n",
      "Epoch 49/50\n",
      "240000/240000 [==============================] - 67s - loss: 0.2072 - acc: 0.9303 - val_loss: 0.8867 - val_acc: 0.8164\n",
      "Epoch 50/50\n",
      "240000/240000 [==============================] - 68s - loss: 0.2068 - acc: 0.9299 - val_loss: 0.8830 - val_acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size = batch_sizes, \n",
    "                    epochs = train_epochs, verbose = 1, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[lrate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('modelqd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTbjAYZAGxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27cc5f2eb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model is overfitting. The next step is to play around the learning rate.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue the training by changing the learn rate manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('modelqd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240000 samples, validate on 120000 samples\n",
      "Epoch 265/270\n",
      "240000/240000 [==============================] - 73s - loss: 0.5695 - acc: 0.8704 - val_loss: 0.3741 - val_acc: 0.9206\n",
      "Epoch 266/270\n",
      "240000/240000 [==============================] - 75s - loss: 0.5432 - acc: 0.8730 - val_loss: 0.3664 - val_acc: 0.9206\n",
      "Epoch 267/270\n",
      "240000/240000 [==============================] - 82s - loss: 0.5258 - acc: 0.8744 - val_loss: 0.3633 - val_acc: 0.9207\n",
      "Epoch 268/270\n",
      "240000/240000 [==============================] - 75s - loss: 0.5133 - acc: 0.8755 - val_loss: 0.3604 - val_acc: 0.9201\n",
      "Epoch 269/270\n",
      "240000/240000 [==============================] - 72s - loss: 0.5000 - acc: 0.8765 - val_loss: 0.3584 - val_acc: 0.9202\n",
      "Epoch 270/270\n",
      "240000/240000 [==============================] - 75s - loss: 0.4889 - acc: 0.8781 - val_loss: 0.3556 - val_acc: 0.9198\n"
     ]
    }
   ],
   "source": [
    "def step_decay1(epoch):\n",
    "    return 0.0001\n",
    "\n",
    "lrate=LearningRateScheduler(step_decay1)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size = batch_sizes, \n",
    "                    epochs = 270, verbose = 1, \n",
    "                    initial_epoch = 264,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119808/120000 [============================>.] - ETA: 0s.\n",
      "Model Accuracy = 0.92\n",
      "Model Loss = 0.38\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(x_test, y_test,\n",
    "          batch_size=batch_sizes)\n",
    "print('.')\n",
    "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
    "print('Model Loss = %.2f' % (evaluation[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('modelqd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error: 3248 out of 40000 or 8.12 %\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_pred)\n",
    "\n",
    "n_count = 0\n",
    "i = 0\n",
    "le = []\n",
    "for r in res:\n",
    "    idx = np.argmax(r)\n",
    "    if idx != y_pred[i]:\n",
    "        n_count = n_count + 1\n",
    "        # w = r.argsort()[-3:][::-1]\n",
    "        # print( classes[y_pred[i]], [classes[y_pred[j]] for j in w] )\n",
    "    i = i + 1\n",
    "\n",
    "print('Total error:', n_count, 'out of', x_pred.shape[0], 'or',n_count/x_pred.shape[0]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 91.88 % out of 40000 dataset\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = (x_pred.shape[0]-n_count) / x_pred.shape[0] * 100\n",
    "print('Prediction accuracy:', pred_accuracy, '% out of', x_pred.shape[0], 'dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy is **91.88 %** out of 40000 dataset"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
